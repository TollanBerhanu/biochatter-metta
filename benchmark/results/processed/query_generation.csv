Full model name,Passed test cases,Total test cases,Accuracy,Iterations
gpt-3.5-turbo-0125,29.0,30.0,0.9666666666666667,5
code-llama-instruct:7:ggufv2:Q4_K_M,29.0,30.0,0.9666666666666667,5
gpt-4-0613,29.0,30.0,0.9666666666666667,5
code-llama-instruct:7:ggufv2:Q8_0,28.8,30.0,0.9600000000000001,5
code-llama-instruct:7:ggufv2:Q5_K_M,28.8,30.0,0.9600000000000001,5
code-llama-instruct:7:ggufv2:Q6_K,28.8,30.0,0.9600000000000001,5
gpt-3.5-turbo-0613,28.4,30.0,0.9466666666666667,5
openhermes-2.5:7:ggufv2:Q3_K_M,28.2,30.0,0.94,5
openhermes-2.5:7:ggufv2:Q2_K,28.2,30.0,0.94,5
llama-2-chat:70:ggufv2:Q4_K_M,27.6,30.0,0.92,5
code-llama-instruct:7:ggufv2:Q2_K,27.6,30.0,0.92,5
openhermes-2.5:7:ggufv2:Q5_K_M,27.4,30.0,0.9133333333333333,5
llama-2-chat:70:ggufv2:Q3_K_M,27.2,30.0,0.9066666666666666,5
llama-2-chat:70:ggufv2:Q5_K_M,27.2,30.0,0.9066666666666666,5
code-llama-instruct:34:ggufv2:Q4_K_M,27.2,30.0,0.9066666666666666,5
llama-2-chat:70:ggufv2:Q2_K,27.0,30.0,0.9,5
code-llama-instruct:34:ggufv2:Q5_K_M,27.0,30.0,0.9,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,26.799999999999997,30.0,0.8933333333333332,5
openhermes-2.5:7:ggufv2:Q8_0,26.4,30.0,0.88,5
code-llama-instruct:7:ggufv2:Q3_K_M,26.2,30.0,0.8733333333333333,5
openhermes-2.5:7:ggufv2:Q4_K_M,26.2,30.0,0.8733333333333333,5
code-llama-instruct:34:ggufv2:Q8_0,25.8,30.0,0.86,5
openhermes-2.5:7:ggufv2:Q6_K,25.8,30.0,0.86,5
code-llama-instruct:34:ggufv2:Q6_K,25.6,30.0,0.8533333333333334,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,25.4,30.0,0.8466666666666666,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,25.4,30.0,0.8466666666666666,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,25.2,30.0,0.84,5
code-llama-instruct:13:ggufv2:Q3_K_M,25.0,30.0,0.8333333333333334,5
gpt-4-0125-preview,25.0,30.0,0.8333333333333334,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,25.0,30.0,0.8333333333333334,5
code-llama-instruct:13:ggufv2:Q4_K_M,25.0,30.0,0.8333333333333334,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,24.8,30.0,0.8266666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,24.8,30.0,0.8266666666666667,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,24.799999999999997,30.0,0.8266666666666665,5
code-llama-instruct:13:ggufv2:Q2_K,24.6,30.0,0.8200000000000001,5
llama-2-chat:13:ggufv2:Q6_K,24.4,30.0,0.8133333333333332,5
code-llama-instruct:13:ggufv2:Q6_K,23.8,30.0,0.7933333333333333,5
llama-2-chat:13:ggufv2:Q8_0,23.6,30.0,0.7866666666666667,5
code-llama-instruct:34:ggufv2:Q3_K_M,23.6,30.0,0.7866666666666667,5
code-llama-instruct:13:ggufv2:Q5_K_M,23.4,30.0,0.7799999999999999,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,23.2,30.0,0.7733333333333333,5
code-llama-instruct:13:ggufv2:Q8_0,23.0,30.0,0.7666666666666667,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,22.8,30.0,0.76,5
llama-2-chat:13:ggufv2:Q4_K_M,22.8,30.0,0.76,5
llama-2-chat:13:ggufv2:Q5_K_M,22.4,30.0,0.7466666666666666,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,21.8,30.0,0.7266666666666667,5
llama-2-chat:7:ggufv2:Q3_K_M,20.8,30.0,0.6933333333333334,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,20.8,30.0,0.6933333333333334,5
code-llama-instruct:34:ggufv2:Q2_K,20.6,30.0,0.6866666666666668,5
llama-2-chat:7:ggufv2:Q2_K,20.6,30.0,0.6866666666666668,5
llama-2-chat:13:ggufv2:Q3_K_M,20.4,30.0,0.6799999999999999,5
llama-2-chat:7:ggufv2:Q6_K,19.8,30.0,0.66,5
llama-2-chat:7:ggufv2:Q4_K_M,19.4,30.0,0.6466666666666666,5
llama-2-chat:7:ggufv2:Q8_0,19.2,30.0,0.64,5
llama-2-chat:7:ggufv2:Q5_K_M,19.0,30.0,0.6333333333333333,5
chatglm3:6:ggmlv3:q4_0,16.6,30.0,0.5533333333333333,5
llama-2-chat:13:ggufv2:Q2_K,13.0,30.0,0.43333333333333335,5
