Full model name,Passed test cases,Total test cases,Accuracy,Iterations
gpt-3.5-turbo-0125,8.0,8.0,1.0,5
openhermes-2.5:7:ggufv2:Q6_K,8.0,8.0,1.0,5
openhermes-2.5:7:ggufv2:Q3_K_M,9.0,9.0,1.0,5
openhermes-2.5:7:ggufv2:Q8_0,8.0,9.0,0.8888888888888888,5
openhermes-2.5:7:ggufv2:Q5_K_M,8.0,9.0,0.8888888888888888,5
openhermes-2.5:7:ggufv2:Q4_K_M,8.0,9.0,0.8888888888888888,5
gpt-4-0613,8.0,9.0,0.8888888888888888,5
gpt-3.5-turbo-0613,8.0,9.0,0.8888888888888888,5
gpt-4-0125-preview,7.0,9.0,0.7777777777777778,5
chatglm3:6:ggmlv3:q4_0,6.0,8.0,0.75,5
openhermes-2.5:7:ggufv2:Q2_K,5.0,9.0,0.5555555555555556,5
mistral-instruct-v0.2:7:ggufv2:Q6_K,4.0,8.0,0.5,5
code-llama-instruct:7:ggufv2:Q3_K_M,4.0,8.0,0.5,5
mixtral-instruct-v0.1:46_7:ggufv2:Q6_K,3.8,8.0,0.475,5
code-llama-instruct:13:ggufv2:Q3_K_M,3.6,8.0,0.45,5
mistral-instruct-v0.2:7:ggufv2:Q5_K_M,4.0,9.0,0.4444444444444444,5
llama-2-chat:7:ggufv2:Q8_0,4.0,9.0,0.4444444444444444,5
llama-2-chat:7:ggufv2:Q5_K_M,4.0,9.0,0.4444444444444444,5
llama-2-chat:7:ggufv2:Q4_K_M,4.0,9.0,0.4444444444444444,5
llama-2-chat:70:ggufv2:Q5_K_M,4.0,9.0,0.4444444444444444,5
llama-2-chat:70:ggufv2:Q4_K_M,4.0,9.0,0.4444444444444444,5
mixtral-instruct-v0.1:46_7:ggufv2:Q5_K_M,3.8,9.0,0.4222222222222222,5
llama-2-chat:7:ggufv2:Q6_K,3.0,8.0,0.375,5
llama-2-chat:70:ggufv2:Q3_K_M,3.0,9.0,0.3333333333333333,5
mixtral-instruct-v0.1:46_7:ggufv2:Q3_K_M,3.0,9.0,0.3333333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q8_0,3.0,9.0,0.3333333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q3_K_M,3.0,9.0,0.3333333333333333,5
llama-2-chat:7:ggufv2:Q3_K_M,3.0,9.0,0.3333333333333333,5
mistral-instruct-v0.2:7:ggufv2:Q4_K_M,3.0,9.0,0.3333333333333333,5
mixtral-instruct-v0.1:46_7:ggufv2:Q4_K_M,3.0,9.0,0.3333333333333333,5
code-llama-instruct:7:ggufv2:Q4_K_M,3.0,9.0,0.3333333333333333,5
mixtral-instruct-v0.1:46_7:ggufv2:Q8_0,2.8,9.0,0.3111111111111111,5
code-llama-instruct:7:ggufv2:Q2_K,2.0,8.0,0.25,5
code-llama-instruct:34:ggufv2:Q8_0,2.0,8.0,0.25,5
mistral-instruct-v0.2:7:ggufv2:Q2_K,2.0,9.0,0.2222222222222222,5
code-llama-instruct:34:ggufv2:Q6_K,1.0,8.0,0.125,5
code-llama-instruct:34:ggufv2:Q5_K_M,1.0,8.0,0.125,5
code-llama-instruct:7:ggufv2:Q5_K_M,1.0,9.0,0.1111111111111111,5
mixtral-instruct-v0.1:46_7:ggufv2:Q2_K,0.0,9.0,0.0,5
code-llama-instruct:13:ggufv2:Q6_K,0.0,8.0,0.0,5
code-llama-instruct:13:ggufv2:Q5_K_M,0.0,8.0,0.0,5
code-llama-instruct:13:ggufv2:Q4_K_M,0.0,8.0,0.0,5
llama-2-chat:7:ggufv2:Q2_K,0.0,9.0,0.0,5
llama-2-chat:70:ggufv2:Q2_K,0.0,9.0,0.0,5
code-llama-instruct:13:ggufv2:Q2_K,0.0,8.0,0.0,5
llama-2-chat:13:ggufv2:Q6_K,0.0,8.0,0.0,5
llama-2-chat:13:ggufv2:Q5_K_M,0.0,9.0,0.0,5
llama-2-chat:13:ggufv2:Q4_K_M,0.0,9.0,0.0,5
llama-2-chat:13:ggufv2:Q3_K_M,0.0,9.0,0.0,5
llama-2-chat:13:ggufv2:Q2_K,0.0,9.0,0.0,5
code-llama-instruct:13:ggufv2:Q8_0,0.0,8.0,0.0,5
code-llama-instruct:34:ggufv2:Q2_K,0.0,8.0,0.0,5
code-llama-instruct:34:ggufv2:Q3_K_M,0.0,8.0,0.0,5
code-llama-instruct:34:ggufv2:Q4_K_M,0.0,8.0,0.0,5
code-llama-instruct:7:ggufv2:Q8_0,0.0,9.0,0.0,5
code-llama-instruct:7:ggufv2:Q6_K,0.0,8.0,0.0,5
llama-2-chat:13:ggufv2:Q8_0,0.0,9.0,0.0,5
